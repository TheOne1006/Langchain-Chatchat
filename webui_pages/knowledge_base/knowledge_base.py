import streamlit as st
from urllib.parse import quote
from streamlit_tags import st_tags
from webui_pages.utils import *
from st_aggrid import AgGrid, JsCode
from st_aggrid.grid_options_builder import GridOptionsBuilder
from configs.server_config import API_SERVER
import pandas as pd
from server.knowledge_base.utils import get_file_path, LOADER_DICT
from server.knowledge_base.kb_service.base import get_kb_details, get_kb_file_details
from typing import Literal, Dict, Tuple
from configs import (kbs_config, KB_ROOT_PATH,
                     EMBEDDING_MODEL, DEFAULT_VS_TYPE,
                     CHUNK_SIZE, OVERLAP_SIZE, ZH_TITLE_ENHANCE)
from server.utils import list_embed_models, list_online_embed_models
import os
import time

# SENTENCE_SIZE = 100

cell_renderer = JsCode("""function(params) {if(params.value==true){return 'âœ“'}else{return 'Ã—'}}""")


def config_aggrid(
        df: pd.DataFrame,
        columns: Dict[Tuple[str, str], Dict] = {},
        selection_mode: Literal["single", "multiple", "disabled"] = "single",
        use_checkbox: bool = False,
) -> GridOptionsBuilder:
    gb = GridOptionsBuilder.from_dataframe(df)
    gb.configure_column("No", width=40)
    for (col, header), kw in columns.items():
        gb.configure_column(col, header, wrapHeaderText=True, **kw)
    gb.configure_selection(
        selection_mode=selection_mode,
        use_checkbox=use_checkbox,
        # pre_selected_rows=st.session_state.get("selected_rows", [0]),
    )
    gb.configure_pagination(
        enabled=True,
        paginationAutoPageSize=False,
        paginationPageSize=10
    )
    return gb


def file_exists(kb: str, selected_rows: List) -> Tuple[str, str]:
    """
    check whether a doc file exists in local knowledge base folder.
    return the file's name and path if it exists.
    """
    if selected_rows:
        file_name = selected_rows[0]["file_name"]
        file_path = get_file_path(kb, file_name)
        if os.path.isfile(file_path):
            return file_name, file_path
    return "", ""


def knowledge_base_page(api: ApiRequest, is_lite: bool = None):
    try:
        kb_list = {x["kb_name"]: x for x in get_kb_details()}
    except Exception as e:
        st.error(
            "è·å–çŸ¥è¯†åº“ä¿¡æ¯é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²æŒ‰ç…§ `README.md` ä¸­ `4 çŸ¥è¯†åº“åˆå§‹åŒ–ä¸è¿ç§»` æ­¥éª¤å®Œæˆåˆå§‹åŒ–æˆ–è¿ç§»ï¼Œæˆ–æ˜¯å¦ä¸ºæ•°æ®åº“è¿æ¥é”™è¯¯ã€‚")
        st.stop()
    kb_names = list(kb_list.keys())
    
    if "selected_kb_name" in st.session_state and st.session_state["selected_kb_name"] in kb_names:
        selected_kb_index = kb_names.index(st.session_state["selected_kb_name"])
    else:
        selected_kb_index = 0
    
    if "selected_kb_info" not in st.session_state:
        st.session_state["selected_kb_info"] = ""
    
    def format_selected_kb(kb_name: str) -> str:
        if kb := kb_list.get(kb_name):
            return f"{kb_name} ({kb['vs_type']} @ {kb['embed_model']})"
        else:
            return kb_name
    
    selected_kb = st.selectbox(
        "è¯·é€‰æ‹©æˆ–æ–°å»ºçŸ¥è¯†åº“ï¼š",
        kb_names + ["æ–°å»ºçŸ¥è¯†åº“"],
        format_func=format_selected_kb,
        index=selected_kb_index
    )
    
    if selected_kb == "æ–°å»ºçŸ¥è¯†åº“":
        with st.form("æ–°å»ºçŸ¥è¯†åº“"):
            
            kb_name = st.text_input(
                "æ–°å»ºçŸ¥è¯†åº“åç§°",
                placeholder="æ–°çŸ¥è¯†åº“åç§°ï¼Œä¸æ”¯æŒä¸­æ–‡å‘½å",
                key="kb_name",
            )
            kb_info = st.text_input(
                "çŸ¥è¯†åº“ç®€ä»‹",
                placeholder="çŸ¥è¯†åº“ç®€ä»‹ï¼Œæ–¹ä¾¿AgentæŸ¥æ‰¾",
                key="kb_info",
            )
            
            cols = st.columns(2)
            
            vs_types = list(kbs_config.keys())
            vs_type = cols[0].selectbox(
                "å‘é‡åº“ç±»å‹",
                vs_types,
                index=vs_types.index(DEFAULT_VS_TYPE),
                key="vs_type",
            )
            
            if is_lite:
                embed_models = list_online_embed_models()
            else:
                embed_models = list_embed_models() + list_online_embed_models()
            
            embed_model = cols[1].selectbox(
                "Embedding æ¨¡å‹",
                embed_models,
                index=embed_models.index(EMBEDDING_MODEL),
                key="embed_model",
            )
            
            submit_create_kb = st.form_submit_button(
                "æ–°å»º",
                # disabled=not bool(kb_name),
                use_container_width=True,
            )
        
        if submit_create_kb:
            if not kb_name or not kb_name.strip():
                st.error(f"çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©ºï¼")
            elif kb_name in kb_list:
                st.error(f"åä¸º {kb_name} çš„çŸ¥è¯†åº“å·²ç»å­˜åœ¨ï¼")
            else:
                ret = api.create_knowledge_base(
                    knowledge_base_name=kb_name,
                    vector_store_type=vs_type,
                    embed_model=embed_model,
                )
                st.toast(ret.get("msg", " "))
                st.session_state["selected_kb_name"] = kb_name
                st.session_state["selected_kb_info"] = kb_info
                st.rerun()
    
    elif selected_kb:
        kb = selected_kb
        st.session_state["selected_kb_info"] = kb_list[kb]['kb_info']
        # ä¸Šä¼ æ–‡ä»¶
        files = st.file_uploader("ä¸Šä¼ çŸ¥è¯†æ–‡ä»¶ï¼š",
                                 [i for ls in LOADER_DICT.values() for i in ls],
                                 accept_multiple_files=True,
                                 )
        kb_info = st.text_area("è¯·è¾“å…¥çŸ¥è¯†åº“ä»‹ç»:", value=st.session_state["selected_kb_info"], max_chars=None,
                               key=None,
                               help=None, on_change=None, args=None, kwargs=None)
        
        if kb_info != st.session_state["selected_kb_info"]:
            st.session_state["selected_kb_info"] = kb_info
            api.update_kb_info(kb, kb_info)
        
        with ((st.expander(
                "çŸ¥è¯†åº“ç½‘ç«™",
                expanded=True,
        ))):
            kb_sites_key = f"kb_sites_{kb}"
            selected_kb_folder_name_key = f"selected_kb_folder_name_key_{kb}"
            
            if kb_sites_key not in st.session_state:
                st.session_state[kb_sites_key] = api.list_sites(kb)
            
            kb_sites = st.session_state.get(kb_sites_key, [])
            
            kb_folder_names = [site.get('folder_name') for site in kb_sites]
            kb_sites_dict = {site["folder_name"]: site for site in kb_sites}
            
            # cache data
            if selected_kb_folder_name_key in st.session_state and st.session_state[selected_kb_folder_name_key] in kb_folder_names:
                selected_kb_site_index = kb_folder_names.index(st.session_state[selected_kb_folder_name_key])
            else:
                selected_kb_site_index = 0
            
            def format_selected_kb_site(kb_folder_name: str) -> str:
                if kb_site := kb_sites_dict.get(kb_folder_name):
                    return f"{kb_site['site_name']} @ ( ID:{kb_site['id']} - ç›®å½•: {kb_site['folder_name']}) "
                else:
                    return kb_folder_name
            
            selected_kb_site = st.selectbox(
                "è¯·é€‰æ‹©æˆ–æ–°å»ºç«™ç‚¹ç›®å½•ï¼š",
                kb_folder_names + ["æ–°å»ºç«™ç‚¹"],
                format_func=format_selected_kb_site,
                index=selected_kb_site_index
            )
            
            cur_kb_site_dict = kb_sites_dict.get(selected_kb_site, {})
            
            site_folder = st.text_input(
                'ç›®å½•',
                placeholder="htmlå­˜æ”¾ç›®å½•",
                key="folder_name",
                value=cur_kb_site_dict.get("folder_name", ""),
                disabled=selected_kb_site != "æ–°å»ºç«™ç‚¹",
            )
            
            site_cols_1 = st.columns(2)
            site_name = site_cols_1[0].text_input(
                'ç½‘ç«™å',
                placeholder="çŸ¥è¯†ç½‘ç«™ååç§°",
                key="site_name",
                value=cur_kb_site_dict.get("site_name", ""),
            )
            
            site_pattern = site_cols_1[1].text_input(
                'æ­£åˆ™',
                placeholder="åŒ¹é…é“¾æ¥çš„æ­£åˆ™",
                key="pattern",
                value=cur_kb_site_dict.get("pattern", ""),
            )
            
            site_cols_2 = st.columns(2)
            site_hostname = site_cols_2[0].text_input(
                'åŸŸåä¿¡æ¯',
                placeholder="https://xxx.com",
                key="hostname",
                value=cur_kb_site_dict.get("hostname", ""),
            )
            site_max_urls = site_cols_2[1].number_input(
                'æœ€å¤§é“¾æ¥æ•°',
                min_value=1,
                max_value=500,
                key="max_urls",
                value=cur_kb_site_dict.get("max_urls", 1),
            )
            
            site_start_urls = st_tags(
                label='èµ·å§‹ç½‘å€ï¼š',
                text="å›è½¦é”®æ·»åŠ å¤šä¸ª",
                value=cur_kb_site_dict.get("start_urls", []),
                maxtags=10,
            )
            
            remove_selectors = st_tags(
                label='ç§»é™¤å…ƒç´ çš„é€‰æ‹©å™¨ï¼š',
                text="å›è½¦é”®æ·»åŠ å¤šä¸ª",
                value=cur_kb_site_dict.get("remove_selectors", []),
                maxtags=10,
            )
            
            # st.write('result', remove_selectors)
            kb_sites_urls_key = f"kb_sites_urls_{kb}_{cur_kb_site_dict.get('id')}"
            
            site_cols_btns = st.columns(3)
            
            if site_cols_btns[0].button(
                    "åˆ›å»ºç«™ç‚¹" if selected_kb_site == "æ–°å»ºç«™ç‚¹" else "æ›´æ–°ç«™ç‚¹",
                    disabled=not (site_pattern and site_name and site_folder
                                  and site_start_urls and site_max_urls and remove_selectors),
                    use_container_width=True,
            ):
                if selected_kb_site == "æ–°å»ºç«™ç‚¹" and not cur_kb_site_dict.get("id"):
                    
                    api.create_kb_site(
                        hostname=site_hostname,
                        site_name=site_name.strip(),
                        folder_name=site_folder.strip(),
                        pattern=site_pattern,
                        knowledge_base_name=kb,
                        start_urls=site_start_urls,
                        remove_selectors=remove_selectors,
                        max_urls=site_max_urls,
                    )
                    st.toast(f"ç«™ç‚¹{site_name}åˆ›å»ºæˆåŠŸ", icon='ğŸ˜')
                    st.session_state[selected_kb_folder_name_key] = site_folder.strip()
                    
                elif cur_kb_site_dict.get("id"):
                    
                    # æ›´æ–°ç«™ç‚¹
                    api.update_kb_site(
                        site_id=cur_kb_site_dict.get("id"),
                        hostname=site_hostname,
                        site_name=site_name.strip(),
                        pattern=site_pattern,
                        knowledge_base_name=kb,
                        start_urls=site_start_urls,
                        remove_selectors=remove_selectors,
                        max_urls=site_max_urls,
                    )
                    st.toast(f"ç«™ç‚¹{site_name}æ›´æ–°æˆåŠŸ", icon='ğŸ˜')
                    st.session_state[selected_kb_folder_name_key] = cur_kb_site_dict.get("folder_name")
                
                time.sleep(2)
                # æ›´æ–°æ•°æ®
                st.session_state[kb_sites_key] = api.list_sites(kb)
                
                time.sleep(1)
                st.rerun()
                
            
            def extract_site_urls_then_download(
                    filter_method: str = "all",
            ):
                extract_data = api.extract_site_urls(hostname=site_hostname,
                                                     pattern=site_pattern,
                                                     start_urls=site_start_urls,
                                                     max_urls=site_max_urls)
                
                links = extract_data.get("links", [])
                
                with st.spinner("æŠ“å–æ•°æ®ä¸­...è¯·å‹¿å…³é—­é¡µé¢æˆ–åˆ·æ–°"):
                    empty = st.empty()
                    empty.progress(0.0, "")
                    for d in api.crawl_site_urls(kb, cur_kb_site_dict.get("id"), links, filter_method):
                        if msg := check_error_msg(d):
                            st.toast(msg)
                        else:
                            empty.progress(d["finished"] / d["total"], d["msg"])
                
            
            
            if site_cols_btns[1].button(
                    "è§£æ&å…¨é‡ä¸‹è½½(å·²å­˜åœ¨é‡æ–°ä¸‹è½½)",
                    type="secondary",
                    disabled=not (
                            site_max_urls and len(site_start_urls) and site_pattern and cur_kb_site_dict.get("id")),
                    use_container_width=True,
            ):
                extract_site_urls_then_download()
                del st.session_state[kb_sites_urls_key]
                st.rerun()
            
            if site_cols_btns[2].button(
                    "è§£æ&å¢é‡ä¸‹è½½(å·²å­˜åœ¨è·³è¿‡)",
                    type="primary",
                    disabled=not (
                            site_max_urls and len(site_start_urls) and site_pattern and cur_kb_site_dict.get("id")),
                    use_container_width=True,
            ):
                extract_site_urls_then_download("new")
                del st.session_state[kb_sites_urls_key]
                st.rerun()
           
            if kb_sites_urls_key not in st.session_state:
                local_urls = api.list_local_site_urls(kb, cur_kb_site_dict.get('folder_name'))
                st.session_state[kb_sites_urls_key] = local_urls
            
            link_df = pd.DataFrame([
                {"url": item['url'],
                 "preview": f"{api.base_url}/knowledge_base/download_doc?" +
                            f"knowledge_base_name={kb}&file_name={quote(item['preview_file'], 'utf-8')}&preview=true"}
                for item in st.session_state.get(kb_sites_urls_key, [])
            ])
            
            st.dataframe(link_df,
                         use_container_width=True,
                         column_config={
                             "url": st.column_config.LinkColumn(
                                 "åŸåœ°å€",
                                 width="medium",
                                 required=True,
                             ),
                             "preview": st.column_config.LinkColumn(
                                 "é¢„è§ˆ",
                                 width="medium",
                                 required=True,
                             ),
                         })
        
        # with st.sidebar:
        with st.expander(
                "æ–‡ä»¶å¤„ç†é…ç½®",
                expanded=True,
        ):
            cols = st.columns(3)
            chunk_size = cols[0].number_input("å•æ®µæ–‡æœ¬æœ€å¤§é•¿åº¦ï¼š", 1, 1000, CHUNK_SIZE)
            chunk_overlap = cols[1].number_input("ç›¸é‚»æ–‡æœ¬é‡åˆé•¿åº¦ï¼š", 0, chunk_size, OVERLAP_SIZE)
            cols[2].write("")
            cols[2].write("")
            zh_title_enhance = cols[2].checkbox("å¼€å¯ä¸­æ–‡æ ‡é¢˜åŠ å¼º", ZH_TITLE_ENHANCE)
        
        if st.button(
                "æ·»åŠ æ–‡ä»¶åˆ°çŸ¥è¯†åº“",
                # use_container_width=True,
                disabled=len(files) == 0,
        ):
            ret = api.upload_kb_docs(files,
                                     knowledge_base_name=kb,
                                     override=True,
                                     chunk_size=chunk_size,
                                     chunk_overlap=chunk_overlap,
                                     zh_title_enhance=zh_title_enhance)
            if msg := check_success_msg(ret):
                st.toast(msg, icon="âœ”")
            elif msg := check_error_msg(ret):
                st.toast(msg, icon="âœ–")
        
        st.divider()
        
        # çŸ¥è¯†åº“è¯¦æƒ…
        # st.info("è¯·é€‰æ‹©æ–‡ä»¶ï¼Œç‚¹å‡»æŒ‰é’®è¿›è¡Œæ“ä½œã€‚")
        doc_details = pd.DataFrame(get_kb_file_details(kb))
        if not len(doc_details):
            st.info(f"çŸ¥è¯†åº“ `{kb}` ä¸­æš‚æ— æ–‡ä»¶")
        else:
            st.write(f"çŸ¥è¯†åº“ `{kb}` ä¸­å·²æœ‰æ–‡ä»¶:")
            st.info("çŸ¥è¯†åº“ä¸­åŒ…å«æºæ–‡ä»¶ä¸å‘é‡åº“ï¼Œè¯·ä»ä¸‹è¡¨ä¸­é€‰æ‹©æ–‡ä»¶åæ“ä½œ")
            doc_details.drop(columns=["kb_name"], inplace=True)
            doc_details = doc_details[[
                "No", "file_name", "document_loader", "text_splitter", "docs_count", "in_folder", "in_db",
            ]]
            # doc_details["in_folder"] = doc_details["in_folder"].replace(True, "âœ“").replace(False, "Ã—")
            # doc_details["in_db"] = doc_details["in_db"].replace(True, "âœ“").replace(False, "Ã—")
            kb_content_path = KB_ROOT_PATH + '/' + kb + '/content/'
            len_ignore_prefix = len(kb_content_path)
            gb = config_aggrid(
                doc_details,
                {
                    ("No", "åºå·"): {},
                    ("file_name", "æ–‡æ¡£åç§°"): {
                        "cellRenderer": JsCode(f"""function(params) {{
                                return params.value.substring({len_ignore_prefix})}}"""),
                    },
                    # ("file_ext", "æ–‡æ¡£ç±»å‹"): {},
                    # ("file_version", "æ–‡æ¡£ç‰ˆæœ¬"): {},
                    ("document_loader", "æ–‡æ¡£åŠ è½½å™¨"): {},
                    ("docs_count", "æ–‡æ¡£æ•°é‡"): {},
                    ("text_splitter", "åˆ†è¯å™¨"): {},
                    # ("create_time", "åˆ›å»ºæ—¶é—´"): {},
                    ("in_folder", "æºæ–‡ä»¶"): {"cellRenderer": cell_renderer},
                    ("in_db", "å‘é‡åº“"): {"cellRenderer": cell_renderer},
                },
                "multiple",
            )
            
            doc_grid = AgGrid(
                doc_details,
                gb.build(),
                columns_auto_size_mode="FIT_CONTENTS",
                theme="alpine",
                custom_css={
                    "#gridToolBar": {"display": "none"},
                },
                allow_unsafe_jscode=True,
                enable_enterprise_modules=False
            )
            
            selected_rows = doc_grid.get("selected_rows", [])
            
            cols = st.columns(4)
            file_name, file_path = file_exists(kb, selected_rows)
            if file_path:
                with open(file_path, "rb") as fp:
                    cols[0].download_button(
                        "ä¸‹è½½é€‰ä¸­æ–‡æ¡£",
                        fp,
                        file_name=file_name,
                        use_container_width=True, )
            else:
                cols[0].download_button(
                    "ä¸‹è½½é€‰ä¸­æ–‡æ¡£",
                    "",
                    disabled=True,
                    use_container_width=True, )
            
            st.write()
            # å°†æ–‡ä»¶åˆ†è¯å¹¶åŠ è½½åˆ°å‘é‡åº“ä¸­
            if cols[1].button(
                    "é‡æ–°æ·»åŠ è‡³å‘é‡åº“" if selected_rows and (
                            pd.DataFrame(selected_rows)["in_db"]).any() else "æ·»åŠ è‡³å‘é‡åº“",
                    disabled=not file_exists(kb, selected_rows)[0],
                    use_container_width=True,
            ):
                file_names = [row["file_name"] for row in selected_rows]
                api.update_kb_docs(kb,
                                   file_names=file_names,
                                   chunk_size=chunk_size,
                                   chunk_overlap=chunk_overlap,
                                   zh_title_enhance=zh_title_enhance)
                st.rerun()
            
            # å°†æ–‡ä»¶ä»å‘é‡åº“ä¸­åˆ é™¤ï¼Œä½†ä¸åˆ é™¤æ–‡ä»¶æœ¬èº«ã€‚
            if cols[2].button(
                    "ä»å‘é‡åº“åˆ é™¤",
                    disabled=not (selected_rows and selected_rows[0]["in_db"]),
                    use_container_width=True,
            ):
                file_names = [row["file_name"] for row in selected_rows]
                api.delete_kb_docs(kb, file_names=file_names)
                st.rerun()
            
            if cols[3].button(
                    "ä»çŸ¥è¯†åº“ä¸­åˆ é™¤",
                    type="primary",
                    use_container_width=True,
            ):
                file_names = [row["file_name"] for row in selected_rows]
                api.delete_kb_docs(kb, file_names=file_names, delete_content=True)
                st.rerun()
        
        st.divider()
        
        cols = st.columns(3)
        
        if cols[0].button(
                "ä¾æ®æºæ–‡ä»¶é‡å»ºå‘é‡åº“",
                # help="æ— éœ€ä¸Šä¼ æ–‡ä»¶ï¼Œé€šè¿‡å…¶å®ƒæ–¹å¼å°†æ–‡æ¡£æ‹·è´åˆ°å¯¹åº”çŸ¥è¯†åº“contentç›®å½•ä¸‹ï¼Œç‚¹å‡»æœ¬æŒ‰é’®å³å¯é‡å»ºçŸ¥è¯†åº“ã€‚",
                use_container_width=True,
                type="primary",
        ):
            with st.spinner("å‘é‡åº“é‡æ„ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå‹¿åˆ·æ–°æˆ–å…³é—­é¡µé¢ã€‚"):
                empty = st.empty()
                empty.progress(0.0, "")
                for d in api.recreate_vector_store(kb,
                                                   chunk_size=chunk_size,
                                                   chunk_overlap=chunk_overlap,
                                                   zh_title_enhance=zh_title_enhance):
                    if msg := check_error_msg(d):
                        st.toast(msg)
                    else:
                        empty.progress(d["finished"] / d["total"], d["msg"])
                st.rerun()
        
        if cols[2].button(
                "åˆ é™¤çŸ¥è¯†åº“",
                use_container_width=True,
        ):
            ret = api.delete_knowledge_base(kb)
            st.toast(ret.get("msg", " "))
            time.sleep(1)
            st.rerun()
